\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Datasets}{1}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Discretization}{1}{subsection.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Cross-Validation}{1}{subsection.2.2}}
\citation{ai}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Missing Values}{2}{subsection.2.3}}
\@writefile{toc}{\contentsline {section}{\numberline {3}$k$-Nearest Neighbors}{2}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Training}{2}{subsection.3.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1}Constructing Probability Table}{2}{subsubsection.3.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Validation}{2}{subsection.3.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Value Distance Metric}{2}{subsubsection.3.2.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}Determining $k$ and $p$}{2}{subsubsection.3.2.2}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Naive Bayes}{2}{section.4}}
\newlabel{nbw}{{4}{2}{Naive Bayes}{section.4}{}}
\newlabel{nb_pd}{{1}{2}{Naive Bayes}{equation.4.1}{}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{kp_cancer}{{1a}{3}{\relax }{figure.caption.1}{}}
\newlabel{sub@kp_cancer}{{a}{3}{\relax }{figure.caption.1}{}}
\newlabel{kp_glass}{{1b}{3}{\relax }{figure.caption.1}{}}
\newlabel{sub@kp_glass}{{b}{3}{\relax }{figure.caption.1}{}}
\newlabel{kp_iris}{{1c}{3}{\relax }{figure.caption.1}{}}
\newlabel{sub@kp_iris}{{c}{3}{\relax }{figure.caption.1}{}}
\newlabel{kp_soybean}{{1d}{3}{\relax }{figure.caption.1}{}}
\newlabel{sub@kp_soybean}{{d}{3}{\relax }{figure.caption.1}{}}
\newlabel{kp_vote}{{1e}{3}{\relax }{figure.caption.1}{}}
\newlabel{sub@kp_vote}{{e}{3}{\relax }{figure.caption.1}{}}
\newlabel{kp_ave}{{1f}{3}{\relax }{figure.caption.1}{}}
\newlabel{sub@kp_ave}{{f}{3}{\relax }{figure.caption.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \relax }}{3}{figure.caption.1}}
\newlabel{kp_plot}{{1}{3}{\relax }{figure.caption.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Training}{3}{subsection.4.1}}
\newlabel{nb_train}{{4.1}{3}{Training}{subsection.4.1}{}}
\newlabel{p_cancer}{{2a}{4}{\relax }{figure.caption.2}{}}
\newlabel{sub@p_cancer}{{a}{4}{\relax }{figure.caption.2}{}}
\newlabel{p_glass}{{2b}{4}{\relax }{figure.caption.2}{}}
\newlabel{sub@p_glass}{{b}{4}{\relax }{figure.caption.2}{}}
\newlabel{p_iris}{{2c}{4}{\relax }{figure.caption.2}{}}
\newlabel{sub@p_iris}{{c}{4}{\relax }{figure.caption.2}{}}
\newlabel{p_soybean}{{2d}{4}{\relax }{figure.caption.2}{}}
\newlabel{sub@p_soybean}{{d}{4}{\relax }{figure.caption.2}{}}
\newlabel{p_vote}{{2e}{4}{\relax }{figure.caption.2}{}}
\newlabel{sub@p_vote}{{e}{4}{\relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces 3D density plots of the naive Bayes probability table for all five datasets. The vertical class axis represents the value of the class, $c$, the attribute axis denotes the index of an attribute, $x$, and the value axis represents the vale of that attribute, $a$. Finally the color is equivalent to the probability of the attibute $x$ having value $a$, and the class having the value $c$\relax }}{4}{figure.caption.2}}
\newlabel{ptable}{{2}{4}{3D density plots of the naive Bayes probability table for all five datasets. The vertical class axis represents the value of the class, $c$, the attribute axis denotes the index of an attribute, $x$, and the value axis represents the vale of that attribute, $a$. Finally the color is equivalent to the probability of the attibute $x$ having value $a$, and the class having the value $c$\relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Validation}{4}{subsection.4.2}}
\citation{Friedman1997}
\citation{Zheng2010}
\citation{ai}
\@writefile{toc}{\contentsline {section}{\numberline {5}TAN}{5}{section.5}}
\newlabel{cmi}{{5}{5}{TAN}{section.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Training}{5}{subsection.5.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Validation}{5}{subsection.5.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.1}Determining Class Probability Distribution}{5}{subsubsection.5.2.1}}
\@writefile{toc}{\contentsline {section}{\numberline {6}ID3}{5}{section.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Training}{5}{subsection.6.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.1}Tree Construction}{5}{subsubsection.6.1.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces An example id3 tree generated for the soybean database.\relax }}{6}{figure.caption.3}}
\newlabel{tan}{{3}{6}{An example id3 tree generated for the soybean database.\relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.2}Pruning}{6}{subsubsection.6.1.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Validation}{6}{subsection.6.2}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Results}{6}{section.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Algorithm Convergence}{6}{subsection.7.1}}
\newlabel{conv}{{7.1}{6}{Algorithm Convergence}{subsection.7.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces \relax }}{7}{figure.caption.4}}
\newlabel{conv_plot}{{4}{7}{\relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Algorithm Precision}{7}{subsection.7.2}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Conclusion}{7}{section.8}}
\bibstyle{apalike}
\bibdata{sources}
\bibcite{Friedman1997}{Friedman et\nobreakspace  {}al., 1997}
\bibcite{ai}{Russel and Norvig, 2010}
\bibcite{Zheng2010}{Zheng and Webb, 2010}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces 1x10 Cross Validation Precision. Green represents the best performing algorithm for each data set. Red represents the worst.\relax }}{8}{table.caption.5}}
\newlabel{table}{{1}{8}{1x10 Cross Validation Precision. Green represents the best performing algorithm for each data set. Red represents the worst.\relax }{table.caption.5}{}}
